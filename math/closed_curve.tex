\documentclass[a4paper,11pt]{article}
\usepackage[scale=0.7,vmarginratio={1:2},heightrounded]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{pgf,tikz}
\usepackage{pgfplots}
\usepackage{enumitem}
%\usepackage[margin=0.5in]{geometry}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}
\theoremstyle{definition}
\newtheorem*{observation}{Observation}
\newtheorem*{example}{Example}
\newtheorem*{remark}{Remark}
\newtheorem{definition}[theorem]{Definition} 

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\dx}{\text{d}}
\newcommand{\D}{\text{D}}
\newcommand{\del}{\partial}
\newcommand{\iff}{\Longleftrightarrow}
\newcommand{\dd}{\text{..}}
\newcommand{\lett}{\sqsupset}


\title{Closed curves}
\author{Erik. S. Gimsing}
\date{January 2018}

\begin{document}
\maketitle
\begin{definition}[Simple closed curve]
	Let $\gamma : [0,1] \rightarrow \R^2$ such that
	\begin{enumerate}
		\item $\forall \varepsilon \in \R_{>0}: \exists \delta \in
			\R_{>0}: |x-a| < \delta \implies 
			\|\gamma(x)-\gamma(a)\|<\varepsilon$
		\item $\forall x,x' \in [0,1): \gamma(x) = \gamma(x') 
			\implies x = x'$
		\item $\gamma(0) = \gamma(1)$
	\end{enumerate}
	Then the map of $\gamma$ is called a simple closed curve.
\end{definition}
\begin{theorem}
	Let $C$ be a simple closed curve in the plane $\R^2$. Then its
	complement, $\R^2\backslash C$, consists of exactly two connected
	components. One of these components is bounded (the interior)
	and the other is unbounded (the exterior), and the curve $C$
	is the boundary of each component.
\end{theorem}
\begin{proof}
	The proof will proceed as follows; first it is proven that the
	theorem holds for curves in the form of a triangle, then it
	is shown that it holds for all polygons by triangulating them,
	then it is proved that every simple closed curve is the limit
	of a polygon approximation.
	
	n-gon approximation of C using convex combinations of map of
	adjacent elements of sequence of lenght n in the
	interval from zero to one
	\begin{equation}
	\begin{aligned}
		&\forall X,Y \subseteq \R^2: d(X,Y) := \sup\ \{\|x-y\|:x\in X \land y 
		\in y\} \\
		&\forall x,y \in [0,1]: K(x,y) = \{z=\gamma(x)t+\gamma(y)(1-t)
		:0\leq t \leq 1\} \\
		&\forall ([a,b] \subseteq \R \land n \in \N): 
		\Delta(n,[a,b]) = \{x_0,x_1,\dots,x_n\}:\\ 
		&(x_0=a \land x_n = b \land x_i<x_{i+1}) \\
		&\forall \Delta(n,[a,b]): S(\Delta(n,[a,b])) := (s_1,\dots,s_n):
		s_i\in [x_{i-1},x_i]: 1<i\leq n\\
		&\forall C: P_n(C) := \{K(s_{i-1},s_i):s_{i-1},s_i\in 
		S(\Delta(n,[0,1]))\}\\
		&\forall \varepsilon \in \R_{>0}: \exists n \in \N_{>0} : d(P_n(C),C)<
		\varepsilon
	\end{aligned}
	\end{equation}
\end{proof}
\newpage
\begin{align*}
	d(t)&=re^{\omega i t} \\
	\\
	d'(t)=v(t)&=i\omega  r e^{\omega i t} \\
	\left|v(t)\right|=u&=\left|i\omega  r e^{\omega i t}\right| \\
	&=\omega \left|r e^{\omega i t}\right|= \omega r \\
	\implies \omega &= \frac{u}{r} \\
	\\
	v'(t)=a(t)&=-\omega^2  r e^{\omega i t} \\
	\left|a(t)\right| &= \left|-\omega^2  r e^{\omega i t}\right| \\
	&= \omega^2 \left|r e^{\omega i t}\right| \\
	&= \omega^2r = \frac{u^2}{r} \\
\end{align*}
\newpage
\begin{align*}
	D_x^n x^k &= \frac{k!\cdot x^{k-n}}{(k-n)!} \\
	D_x^\alpha x^k &= \frac{\Gamma(k+1)\cdot x^{k-\alpha}}
	{\Gamma(k-\alpha+1)} \\
	\\
	\text{Linearity}\\
	D_x^\alpha \lambda x^k &= \frac{\Gamma(k+1)\cdot \lambda x^{k-\alpha}}
	{\Gamma(k-\alpha+1)} \\
	&=\lambda D_x^\alpha x^k \\
	\\
	D_x^\alpha x^m+ D_x^\alpha x^k &:= D_x^\alpha (x^m+x^k)\\
	\\
	D_x^\alpha D_x^\beta x^k &= D_x^\alpha\left(
	\frac{\Gamma(k+1)\cdot x^{k-\beta}}{\Gamma(k-\beta+1)}\right) \\
	&=\frac{\Gamma(k+1)}{\Gamma(k-\beta+1)}
	D_x^\alpha x^{k-\beta}\\
	&=\frac{\Gamma(k+1)}{\Gamma(k-\beta+1)}
	\frac{\Gamma(k-\beta+1)\cdot x^{k-\beta-\alpha}}
	{\Gamma(k-\beta-\alpha+1)}\\
	&=\frac{\Gamma(k+1)\cdot x^{k-\beta-\alpha}}
	{\Gamma(k-\beta-\alpha+1)} = D_x^{\alpha + \beta}x^k
\end{align*}
\begin{align*}
	\sin(x+\pi/2) = \cos(x),&\ \cos(x+\pi/2) = -\sin (x),\\
	-\sin(x+\pi/2) = -\cos(x),&\ -\cos(x+\pi/2) = \sin(x) \\
	\\
	D_x^n \sin x &= \sin \left(x+\frac{\pi n}{2}\right) \\
	D_x^n \cos x &= \cos \left(x+\frac{\pi n}{2}\right) \\
	\\
	D_x^\alpha \sin x &= \sin \left(x+\frac{\pi \alpha}{2}\right) \\
	D_x^\alpha \cos x &= \cos \left(x+\frac{\pi \alpha}{2}\right) \\
	\\
	D_x^\alpha D_x^\beta \sin x 
	&= 	D_x^\alpha \sin \left(x+\frac{\pi \beta}{2}\right) \\
	&= 	\sin \left(x+\frac{\pi \beta}{2}+\frac{\pi \beta}{2}\right) \\
	&= 	\sin \left(x+\frac{\pi (\alpha+\beta)}{2}\right) 
	= D_x^{\alpha+\beta} \sin x\\
	\\
	D_x^\alpha D_x^\beta \cos x 
	&= 	D_x^\alpha \cos \left(x+\frac{\pi \beta}{2}\right) \\
	&= 	\cos \left(x+\frac{\pi \beta}{2}+\frac{\pi \beta}{2}\right) \\
	&= 	\cos \left(x+\frac{\pi (\alpha+\beta)}{2}\right) 
	= D_x^{\alpha+\beta} \cos x\\
\end{align*}
\begin{align*}
	D_x^n e^{\lambda x} &= \lambda^n e^{\lambda x} \\
	D_x^\alpha e^{\lambda x} &= \lambda^\alpha e^{\lambda x} \\
	\\
	D_x^\alpha D_x^\beta e^{\lambda x} &= D_x^\alpha\left( \lambda^\beta
	e^{\lambda x}\right) \\
	&= \lambda^\beta D_x^\alpha e^{\lambda x} \\
	&= \lambda^\beta \lambda^\alpha e^{\lambda x} 
	= \lambda^{\alpha+\beta} e^{\lambda x}\\
\end{align*}
\newpage
\begin{align*}
	mv' &= mg - kv^2 \\
	\frac{1}{g} v' &= 1 - \frac{k}{mg}v^2 \\
	\frac{1}{g}\frac{1}{1 - \frac{k}{mg}v^2} v' &= 1 \\
	\frac{1}{g}\int \frac{1}{1 - \frac{k}{mg}v^2} v'\ \text{d}t &= t+C \\
	\frac{1}{g}\int \frac{\text{d}v}{1 - \frac{k}{mg}v^2}  &= t+C \\
	\text{Let } u^2 = \frac{k}{mg}v^2 &\implies \text{d}u = \sqrt{k/mg} \\
	\frac{1}{g}\int\frac{\sqrt{k/mg}}{\sqrt{k/mg}} \frac{\text{d}v}{1 - 
	\frac{k}{mg}v^2}  &= t+C \\
	\sqrt{gk/m}\int \frac{\text{d}u}{1-u^2}&=t+C \\
	\sqrt{gk/m} \tanh^{-1} u&=t+C \\
	\sqrt{gk/m} \tanh^{-1}{\left(v\sqrt{k/mg}\right)} &=t+C \\
	v(t) &= \sqrt{mg/k} \tanh{\left(t\sqrt{m/gk}\right)} 
\end{align*}
\begin{align*}
	J&=\int \frac{x^2}{x^3+4}\ \text{d}x \\
	\text{Let } u = x^3+4 &\implies \text{d}u = 3x^2\ \text{d}x \\
	J&=\int \frac{3}{3}\frac{x^2}{x^3+4}\ \text{d}x \\
	 &=\frac{1}{3}\int \frac{\text{d}u}{u} \\
	 &=\frac{1}{3} \ln{\left|x^3+4\right|}
\end{align*}
\begin{align*}
	J&=\int \sin^3 (x)\cos(x)\ \text{d}x \\
	\text{Let } u = \sin x &\implies \text{d}u = \cos x\ \text{d}x \\
	J&=\int u^3\ \text{d}u \\
	 &=\frac{u^4}{4} = \frac{\sin{(x)}^4}{4} \\
\end{align*}
\begin{align*}
	J&=\int \frac{\ln^2 x}{x}\ \text{d}x \\
	\text{Let } u = \ln x &\implies \text{d}u = \frac{1}{x}\ \text{d}x \\
	J&=\int u^2\ \text{d}u \\
	 &=\frac{u^3}{3} = \frac{\ln{(x)}^3}{3} \\
\end{align*}
\begin{align*}
	J&=\int x \cos{\left(5x^2\right)}\ \text{d}x \\
	\text{Let } u = 5x^2 &\implies \text{d}u = 10x\ \text{d}x \\
	J&=\frac{1}{10}\int \cos u\ \text{d}u \\
	 &= \frac{\sin{\left(5x^2\right)}}{10} 
\end{align*}
\begin{align*}
	J&=\int (2x+5){(x^2+5x)}^7\ \text{d}x \\
	\text{Let } u = x^2+5x &\implies \text{d}u = 2x+5\ \text{d}x \\
	J&=\int u^7\ \text{d}u \\
	 &=\frac{{\left(x^2+5x\right)}^8}{8} \\
\end{align*}
\begin{align*}
	J&=\int {(3-x)}^{10}\ \text{d}x \\
	\text{Let } u = 3-x &\implies \text{d}u = - \text{d}x \\
	J&=-\int u^{10}\ \text{d}u \\
	 &=\frac{{\left(3-x\right)}^{11}}{11} \\
\end{align*}
\begin{align*}
	J&=\int \sqrt{(7x-9)}\ \text{d}x \\
	\text{Let } u = 7x-9 &\implies \text{d}u = 7\ \text{d}x \\
	J&=\frac{1}{7}\int \sqrt{u}\ \text{d}u \\
	 &=\frac{{2\left(7x-9\right)}^{1.5}}{21} \\
\end{align*}
\begin{align*}
	J&=\int \frac{x^3}{\sqrt[3]{1+x^4}}\ \text{d}x \\
	\text{Let } u = 1+x^4 &\implies \text{d}u = 4x^3\ \text{d}x \\
	J&=\frac{1}{4}\int \frac{1}{\sqrt[3]{u}}\ \text{d}u \\
	 &=\frac{{2\left(1+x^4\right)}^{2/3}}{12} \\
\end{align*}
\begin{align*}
	J&=\int e^{5x+2}\ \text{d}x \\
	\text{Let } u = 5x+2 &\implies \text{d}u = 5\ \text{d}x \\
	J&=\frac{1}{5}\int e^u\ \text{d}u \\
	 &=\frac{1}{5}e^{5x+2} \\
\end{align*}
\begin{align*}
	J&=\int 4\cos 3x\ \text{d}x \\
	\text{Let } u = 3 &\implies \text{d}u = 3\ \text{d}x \\
	J&=\frac{4}{3}\int \cos u\ \text{d}u \\
	 &=\frac{4}{3}\sin 3x \\
\end{align*}
\begin{align*}
	J&=\int \frac{\sin(\ln x)}{x}\ \text{d}x \\
	\text{Let } u = \ln x &\implies \text{d}u = \frac{1}{x}\ \text{d}x \\
	J&=\int \sin u\ \text{d}u \\
	 &=-\cos(\ln x) \\
\end{align*}
\begin{align*}
	J&=\int \frac{3x+6}{x^2+4x-3}\ \text{d}x \\
	\text{Let } u = x^2+4x-3 &\implies \text{d}u = 2x+4\ \text{d}x \\
	J&=\frac{3}{2}\int \frac{1}{u}\ \text{d}u \\
	 &=\frac{3}{2}\ln \left|x^2+4x-3\right| \\
\end{align*}
\begin{align*}
	J&=\int x 3^{x^2+1}\ \text{d}x \\
	\text{Let } u = x^2+1 &\implies \text{d}u = 2x\ \text{d}x \\
	J&=\frac{1}{2}\int 3^u\ \text{d}u \\
	 &=\frac{3^{x^2+1}}{2\ln 3} \\
\end{align*}
\begin{align*}
	J&=\int \frac{3}{x\ln x}\ \text{d}x \\
	\text{Let } u = \ln x &\implies \text{d}u = \frac{1}{x}\ \text{d}x \\
	J&=3\int \frac{1}{u}\ \text{d}u \\
	 &=3 \ln \left|\ln |x|\right| \\
\end{align*}
\begin{align*}
	J&=\int \frac{\cos 5x}{e^{\sin 5x}}\ \text{d}x \\
	\text{Let } u = \sin 5x &\implies \text{d}u = 5\cos 5x\ \text{d}x \\
	J&=\frac{1}{5}\int e^{-u}\ \text{d}u \\
	 &=\frac{1}{5} e^{-\sin 5x} \\
\end{align*}
\begin{align*}
	J&=\int_{0}^{\sqrt{\pi}} x\sin x^2\ \text{d}x \\
	\text{Let } u = x^2 &\implies \text{d}u = 2x\ \text{d}x \\
	J &= \frac{1}{2}\int_0^{\pi} \sin u\ \text{d}u \\
	  &= \frac{1}{2} (-\cos \pi + \cos 0) = 1
\end{align*}
\begin{align*}
	J&=\int (x+3){(x-1)}^5\ \text{d}x \\
	\text{Let } u = x-1 &\implies \text{d}u = \ \text{d}x \\
	J&=\int (u+4)u^5\ \text{d}u \\
	 &= \int u^6 \ \text{d}u + \int 4u^5\ \text{d}u \\
	 &= \frac{{(x-1)}^7}{7} + \frac{4{(x-1)}^6}{6}
\end{align*}
\begin{align*}
	J&=\int x \sqrt{4-x}\ \text{d}x \\
	\text{Let } u = 4-x &\implies \text{d}u = - \text{d}x \\
	J&= -\int (4-u)\sqrt{u}\ \text{d}u \\
	 &= \int u^{3/2}\ \text{d}u - \int 4\sqrt{u} \ \text{d}u \\
	 &= \frac{2{(4-x)}^{5/2}}{5} - \frac{8{(4-x)}^{3/2}}{3}
\end{align*}
\begin{align*}
	J&=\int \frac{x+5}{2x+3}\ \text{d}x \\
	\text{Let } u = 2x+3 &\implies \text{d}u = 2\ \text{d}x \\
						 &\implies x = \frac{u-3}{2} \\
	J&= \frac{1}{2}\int \frac{u/2-3/2+5}{u}\ \text{d}u \\
	 &= \frac{u}{4} + \frac{7}{4}\int \frac{\text{d}u}{u}  \\
	 &= \frac{u}{4} + \frac{7}{4}\ln |u|  \\
	 &= \frac{2x+3}{4} + \frac{7}{4}\ln |2x+3|  \\
\end{align*}
\begin{align*}
	J&=\int \frac{x^2+4}{x+2}\ \text{d}x \\
	\text{Let } u = x+2 &\implies \text{d}u = \text{d}x \\
						&\implies x = u-2 \\
	J&= \int \frac{{(u-2)}^2+4}{u}\ \text{d}u \\
	 &= \int \frac{u^2-4u+8}{u}\ \text{d}u \\
	 &= \int u\ \text{d}u -4 \int\ \text{d}u+8\int\frac{\text{d}u}{u} \\
	 &= \frac{{(x+2)}^2}{2} -4x-8+8 \ln \left|x+2\right|
\end{align*}
\begin{align*}
	J&=\int \frac{{(3 +\ln x)}^2(2-\ln x)}{4x}\ \text{d}x \\
	\text{Let } u = 3+\ln x &\implies \text{d}u =\frac{1}{x} \ \text{d}x \\
						&\implies -\ln x = 3-u \\
	J&= \frac{1}{4}\int u^2(5-u)\ \text{d}u \\
	 &= \frac{5}{4}\int u^2\ \text{d}u -\frac{1}{4}\int u^3\ \text{d}u \\
	 &= \frac{5u^3}{12}-\frac{u^4}{16} =\frac{5{(3+\ln x)}^3}{12}
										-\frac{{(3+\ln x)}^4}{16}
\end{align*}
\begin{align*}
	J&=\int_0^9 \sqrt{4-\sqrt{x}}\ \text{d}x \\
	\text{Let } u = 4-\sqrt{x} &\implies \sqrt{x} =4-u \\
							   &\implies x = u^2-8u+16 \\
							   &\implies \text{d}x = 2u-8\ \text{d}u\\
	J&= \int_4^1 \sqrt{u}(2u-8)\ \text{d}u \\
	 &= 2\int_4^1 u^{3/2}\ \text{d}u - 8 \int_4^1 \sqrt{u} \ \text{d}u \\
	 &= \frac{4u^{5/2}}{5} \bigg|_4^1- \frac{16u^{3/2}}{3} \bigg|_4^1\\
	 &= \left(\frac{4\cdot 1^{5/2}}{5}-\frac{4\cdot 4^{5/2}}{5}\right)
	-\left(\frac{16\cdot 1^{3/2}}{3}-\frac{16\cdot 4^{3/2}}{3}\right)\\
	&= -\frac{124}{5} + \frac{112}{3} = \frac{188}{10}
\end{align*}
\begin{align*}
	\frac{\dx y}{\dx x} &= y(b-ay) \\
	\frac{1}{y(b-ay)}\frac{\dx y}{\dx x} &= 1 \\
	\int \frac{1}{y(b-ay)}\frac{\dx y}{\dx x}\ \dx x &= x \\
	J=\int \frac{1}{y(b-ay)}\ \dx y &= x \\
	\\
	\frac{1}{y(b-ay)} &= \frac{A}{y}+\frac{B}{b-ay} \\
					  &= \frac{A(b-ay)+By}{y(b-ay)}\\
					1 &= A(b-ay)+By \\
					  &= Ab - aAy+By, \text{ Let } A =\frac{1}{b} \\
					0 &= By-\frac{ay}{b} \implies B = \frac{a}{b} \\
	\\
	J&= \frac{1}{b}\int\frac{\dx y}{y}+\frac{a}{b}\int\frac{1}{b-ay}\ \dx y \\
	\text{Let } u = b-ay &\implies \dx u = -a\ \dx y \\
	J&= \frac{\ln y}{b}-\frac{1}{b}\int\frac{\dx u}{u} \\
	 &= \frac{\ln y}{b}-\frac{\ln b-ay}{b}\\
	\frac{\ln y}{b}-\frac{\ln( b-ay)}{b} &= x \\
	\ln y - \ln (b-ay) &= bx\\
	\ln {\left(\frac{y}{b-ay}\right)} &= bx \\
	\frac{y}{b-ay} &= e^{bx}\\
	\frac{b-ay}{y} &= e^{-bx}\\
	\frac{b}{y} &= a+e^{-bx}\\
	\frac{y}{b} &=\frac{1}{a+e^{-bx}}\\
	y &=\frac{b}{a+e^{-bx}}
\end{align*}
\begin{align*}
	\frac{\dx N}{\dx t} &= rN\left(1-\frac{N}{K}\right) \\
	\frac{1}{N\left(1-\frac{N}{K}\right)}\frac{\dx N}{\dx t} &= r \\
	\int\frac{1}{N\left(1-\frac{N}{K}\right)}\frac{\dx N}{\dx t}\ \dx x&=rt+C \\
	I = \int\frac{1}{N\left(1-\frac{N}{K}\right)}\ \dx N&=rt+C \\
	\frac{1}{N\left(1-\frac{N}{K}\right)}
	&=\frac{A}{N}+\frac{B}{1-\frac{N}{K}}\\
	&=\frac{A\left(1-\frac{N}{K}\right)+BN}{N\left(1-\frac{N}{K}\right)}\\
	1&=A-\frac{AN}{K}+BN, \text{ Let } A= 1\\
	0&=BN-\frac{N}{K} \implies B= \frac{1}{K} \\
	I&=\int \frac{\dx N}{N}+\frac{1}{K}\int \frac{1}{1-\frac{N}{K}}\ \dx N\\
	\text{Let } u = 1-\frac{N}{K}&\implies \dx u = -\frac{1}{K}\ \dx N\\
	I&= \ln N - \int \frac{\dx u}{u}\\
	 &= \ln N - \ln \left(1-\frac{N}{K}\right) \\
	\ln N - \ln \left(1-\frac{N}{K}\right) &= rt+C\\
	\ln \left(\frac{N}{1-\frac{N}{K}}\right) &= rt+C\\
	\frac{N}{1-\frac{N}{K}} &= Ce^{rt}\\
	\frac{1-\frac{N}{K}}{N} &= Ce^{-rt}\\
	\frac{1}{N} &=\frac{1}{K}+ Ce^{-rt}\\
	N(t) &=\frac{1}{\frac{1}{K}+ Ce^{-rt}}\\
	N_0 = N(0) = \frac{1}{\frac{1}{K}+C} &\implies C = \frac{1}{N_0}-\frac{1}{K}
\end{align*}
\begin{align*}
	J&=\int \frac{1}{1+e^x}\ \dx x\\
	 &=\int \frac{e^{-x}}{e^{-x}}\frac{1}{1+e^x}\ \dx x\\
	 &=\int \frac{e^{-x}}{1+e^{-x}}\ \dx x\\
	\text{Let } u=1+e^{-x} &\implies \dx u = -e^{-x}\ \dx x\\
	J&=-\int \frac{\dx u}{u}\\
	 &= -\ln u = -\ln \left(1+e^{-x}\right)
\end{align*}
\begin{align*}
	\int fg' = \int f'g+fg
\end{align*}
\begin{align*}
	J&=\int_0^\infty \left(xe^{1-x}
	-\lfloor x\rfloor e^{1-\lfloor x \rfloor}\right)\ \dx x\\
	&=\int_0^\infty xe^{1-x}\ \dx x-
	\int_0^\infty\lfloor x\rfloor e^{1-\lfloor x \rfloor}\ \dx x\\
	I_1&=\int_0^\infty\lfloor x\rfloor e^{1-\lfloor x \rfloor}\ \dx x\\
	&=\sum_{n=0}^\infty ne^{1-n}=e\sum_{n=1}^\infty ne^{-n}\\
	\frac{1}{e^1}+\frac{2}{e^2}&=\frac{e^1+2}{e^2}\\
	\frac{1}{e^1}+\frac{2}{e^2}+\frac{3}{e^3}&=\frac{e^2+2e^1+3}{e^3}\\
	\sum_{n=1}^\infty ne^{-n}&=\lim_{m\rightarrow\infty}
	\frac{1}{e^m}\sum_{n=0}^{m-1}(m-n)e^{n}\\
\end{align*}
\newpage
\begin{theorem}[Continues Image of Closed Interval Is Closed Interval]
	Let $I\subseteq \R$ be a set such that
	\begin{equation}
	\begin{aligned}
		\forall x,y\in I: \forall z\in R: (x<z<y\implies z\in I)
	\end{aligned}
	\end{equation}
	and let $f:I\rightarrow \R$ be a continues real function. Then the image of
	$f$ also satisfies the above.
\end{theorem}
\begin{proof}
\end{proof}
\begin{theorem}[Intermediate Value Theorem]\label{th1}
	Let $f$ be a real function which is continues on $[a,b]$ such that
	$f(a)<f(b)$. Then for $f(a)<k<f(b)$:
	\begin{equation}
	\begin{aligned}
		\exists c \in (a,b):f(c) =k
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
	Let $A=\{x\in[a,b]:f(z)<k\}$. Then $A\neq\emptyset$ since
	$a\in A$ and $\sup A$ exists since $b$ is an upper bound. Let
	$c =\sup A$, we claim $f(c)=k$.  Since $c$ is the supremum,
	there is $\delta_0\in\R_{>0}$ such that for $0<c-a'<\delta_0$
	we have both $a'\in A$ and by the continuity of $f$
	\begin{equation}
	\begin{aligned}
		|f(a')-f(c)|<\varepsilon
	\end{aligned}
	\end{equation}
	for all $\varepsilon\in\R_{>0}$. Then 
	\begin{equation}
	\begin{aligned}
		|f(a')-f(c)|&<\varepsilon\\
		|f(c)-f(a')|&<\varepsilon\\
		\implies f(c)&<f(a')+\varepsilon\\
		\implies f(c)&<k+\varepsilon,\ \because f(a')<k
	\end{aligned}
	\end{equation}
	we may also choose $\delta_1\in\R_{>0}$ such that for $0<b'-c<\delta_1$ we
	have both $b'\notin A$ and
	\begin{equation}
	\begin{aligned}
		|f(b')-f(c)|&<\varepsilon\\
		|f(c)-f(b')|&<\varepsilon\\
		\implies f(b')-\varepsilon&<f(c)\\
		\implies k-\varepsilon&<f(c),\ \because k\leq f(b')
	\end{aligned}
	\end{equation}
	let $\delta=\min(\delta_0,\delta_1)$, then we have
	\begin{equation}
	\begin{aligned}
		0<|x-c|<\delta\implies |f(x)-k|<\varepsilon \iff \lim_{x\rightarrow
		c}f(x)=k
	\end{aligned}
	\end{equation}
	so by the continuity of $f$ we have $f(c)=k$.
\end{proof}
\begin{theorem}[Rolle's Theorem]
	Let $f$ be a real function which is continues on $[a,b]$ and differntiable
	on $(a,b)$ such that $f(a)=f(b)$. Then
	\begin{equation}
	\begin{aligned}
		\exists \xi \in (a,b):f'(\xi) =0
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
	Proof sketch: Use that image of interval is interval, and that it has max
	and min. Then consider the case of a constant function and when not use that
	max and min have $f'=0$.
\end{proof}
\begin{theorem}[Mean Value Theorem]
	Let $f$ be a real function which is continues on $[a,b]$ and differntiable
	on $(a,b)$. Then:
	\begin{equation}
	\begin{aligned}
		\exists \xi \in (a,b):f'(\xi) =\frac{f(b)-f(a)}{b-a}
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
	Let $g(x)=f(x)-\frac{f(b)-f(a)}{b-a}(x-a)$. Then $g$ is continues on
	$[a,b]$, and differntiable on $(a,b)$. Note that $g(a)=f(a)$ and
	$g(b)=f(a)$, therefore by Rolle's Theorem there is $\xi\in(a,b)$ such that
	\begin{equation}
	\begin{aligned}
		g'(\xi) &= 0\\
		f'(\xi)-\frac{f(b)-f(a)}{b-a} &= 0\\
		f'(\xi) &= \frac{f(b)-f(a)}{b-a}
	\end{aligned}
	\end{equation}
	Which completes the proof.
\end{proof}
\begin{theorem}[Cauchy Mean Value Theorem]
	Let $f$ and $g$ be real functions which are continues on $[a,b]$ and 
	differntiable on $(a,b)$. Then:
	\begin{equation}
	\begin{aligned}
		\exists \xi \in (a,b):(f(b)-f(a))g'(\xi)=(g(b)-g(a))f'(\xi)
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
\end{proof}
\begin{theorem}[L'H\^{o}pital's Rule]
	Let $f$ and $g$ be real functions which are continues on $[a,b]$ and 
	differntiable on $(a,b)$. Let $g'(x)\neq 0$ for all $x\in(a,b)$ and suppose
	there is some $c\in(a,b)$ such that $f(c)=g(c)=0$, then
	\begin{equation}
	\begin{aligned}
		\lim_{x\rightarrow c}\frac{f(x)}{g(x)}
		=\lim_{x\rightarrow c}\frac{f'(x)}{g'(x)}
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
\end{proof}
\begin{theorem}[Mean Value Theorem for Integrals]
	Let $f$ be a continues real function on the closed interval $[a,b]$. Then:
	\begin{equation}
	\begin{aligned}
		\exists k \in [a,b]: \int_a^b f(x) \dx x = f(k)(b-a)
	\end{aligned}
	\end{equation}
\end{theorem}
\begin{proof}
\end{proof}
\newpage
\begin{align*}
	f(x)=x^3-x^2-8x+1 &\implies f'(x)=3x^2-2x-8\\
	3x^2-2x-8 &= 0\\
	\therefore x &= -4/3,\ 2\\
	\therefore \max(f([-2,2]))&=\max(\{f(-4/3),f(2),f(-2)\})=f(-4/3)\\
	\land \min(f([-2,2]))&=\min(\{f(-4/3),f(2),f(-2)\})=f(2)
\end{align*}
\begin{align*}
	\lett a_1<\cdots<a_n\land \lett f(x)=\sum_{i=1}^n {(x-a_i)}^2\\
	\therefore \D_x f(x)=\sum_{i=1}^n \D_x{(x-a_i)}^2=
	\sum_{i=1}^n 2(x-a_i)\\
	\therefore 0=\sum_{i=1}^n 2(x'-a_i)=2nx'-\sum_{i=1}^n 2a_i\\
	\implies x'=\frac{1}{n}\sum_{i=1}^n a_i \implies \min f = f(x')\because
	0\leq {(x-a_i)}^2
\end{align*}
\begin{align*}
	&\lett a_1<\cdots<a_n\land \lett f(x)=\sum_{i=1}^n |x-a_i|\\
	\forall i<j:&x<a_i<a_j \implies 0<|x-a_i|+|x-a_j|=-2x+a_i+a_j\\
				&a_i\leq x'\leq a_j\implies0<|x-a_i|+|x-a_j|=a_j-a_i\\
				& a_i<a_j<x'' \implies 0<|x-a_i|+|x-a_j|=2x-a_i-a_j\\
	\therefore& a_j-a_i=2a_j-a_i-a_j<2x''-a_i-a_j\\
	\therefore& a_j-a_i=-2a_i+a_i+a_j<-2x+a_i+a_j\\
	\therefore\min f &= \min \sum_{i=1}^n |x-a_i| 
	= a_n-a_1+\min \sum_{i=2}^{n-1} |x-a_i|\\
	\therefore 2\mid n &\implies \min f= a_n-a_i+\cdots+a_{n/2+1}-a_{n/2-1}\\
	\therefore 2\nmid n &\implies \min f=a_n-a_i+\cdots+a_{n-\lfloor n/2\rfloor}
\end{align*}
\begin{align*}
	\lett 0<a \land \lett &f(x)=\frac{1}{1+|x|}+\frac{1}{1+|x-a|}\\
	\lett x< 0 &\implies f(x)=\frac{1}{1-x}+\frac{1}{1-x+a}\\&\implies
	f'(x)=\frac{1}{{(1-x)}^2}+\frac{1}{{(a+1-x)}^2}>0\\
	\lett 0<x< a &\implies f(x)=\frac{1}{1+x}+\frac{1}{1-x+a}\\&\implies
	f'(x)=-\frac{1}{{(1+x)}^2}+\frac{1}{{(a+1-x)}^2}\\
	&\therefore f'(x)=0\implies x=a/2\\
	\lett a< x &\implies f(x)=\frac{1}{1+x}+\frac{1}{1+x-a}\\&\implies
	f'(x)=-\frac{1}{{(1+x)}^2}-\frac{1}{{(x+1-a)}^2}<0\\
	\therefore \min f=\min \{f(a/2),f(a),f(0)\}&=\min\{f(a/2),f(0)\}\because
	f(0)=f(a)\\
	f(0)=1+\frac{1}{1+a}=\frac{a+2}{a+1}&\land f(a/2)=\frac{4}{2+a}\\
	0<a^2\iff 4a+4&<{(a+2)}^2\iff \frac{4}{2+a}<\frac{a+2}{a+1}\\
	\therefore \min f =\frac{a+2}{a+1}
\end{align*}
\newpage
\begin{align*}
	\cos 2\theta + i \sin 2\theta &= e^{2i\theta } \\
								  &= {\left(e^{i\theta }\right)}^2 \\
								  &= {\left(\cos \theta+i\sin \theta\right)}^2\\
								  &= \cos^2 \theta 
									 + 2i \sin \theta \cos \theta - \sin^2 \\
	\implies &\cos 2\theta = \cos^2 \theta - \sin^2 \theta \\
	\implies &\sin 2\theta = 2 \sin \theta \cos \theta \\
	\implies &\cos \theta = \frac{\sin 2\theta}{2\sin \theta}
\end{align*}
\begin{definition}
\begin{align*}
	U_n := \{z\in \C: z^n = 1\} \\
\end{align*}
\end{definition}
\begin{theorem}
\begin{align*}
	\forall n \in \N: \forall z\in \C:  
	(z^n = 1 \implies \exists k \in \N_n : z = e^{2i k\pi / n})
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
	&P_1:=
	\forall n \in \N: \forall z\in \C: \exists U_n= \{z_1,\dots,z_n\} 
	\subseteq \C:
	\forall 1 \leq i \leq n: z_i^n = 1 
	&& \text{(FTA)} \\
	&\forall k \in \N_n: {\left(e^{2ik \pi /n}\right)}^n = e^{2\pi i k} = 1,\
	\therefore \exists \{c_1,\dots,c_n\} \subseteq
	\C,\ \because\left|\N_n\right|=n \\
	&\exists z\in U_n : \forall k \in \N_n: e^{2ik \pi /n} = z \implies
	\exists c \notin U_n: c^n = 1 \implies \bot\ \because P_1
\end{align*}
\end{proof}
\begin{theorem}
\begin{align*}
	(U_n,\cdot) \cong (\Z/n\Z,+)
\end{align*}
\end{theorem}
\begin{proof}
\begin{align*}
	\lett\varphi:\Z/n\Z \rightarrow U_n: \varphi(k)=e^{2ik \pi /n}\\
	\lett k,m\in\Z/n\Z\land\varphi(k+m)=e^{2i(k+m) \pi /n}
	=e^{2ik \pi /n}e^{2im \pi/n}
	=\varphi(k)\varphi(m)\\
	\lett k,m\in\Z/n\Z\land \varphi(k)=\varphi(m)\iff e^{2ik \pi /n}
	=e^{2im \pi/n}
	\iff e^{2i(k-m) \pi /n}=1\\
	\therefore k=m\ \because -n<k-m<n \land e^0=1\\
	\text{Theorem 10}\implies\forall \omega\in U_n:\exists 
	k\in\Z/n\Z:\varphi(k)=\omega\\
	\therefore \exists \gamma:U_n\rightarrow \Z/n\Z:\forall \omega\in U_n,k\in
	\Z/n\Z:(\gamma(\varphi(\omega))=\omega\land\varphi(\gamma(k))=k)
\end{align*}
\end{proof}
\begin{theorem}
	Let $f$ be continues on $[a,b]$ and $f(a)<f(b)$. Then $f$ is
	injective on $[a,b]$ if and only if $f$ is strictly increasing
	on $[a,b]$
\end{theorem}
\begin{proof}
	\textbf{Necessary condition} (Injective $\implies$ Strictly increasing)

	First we show that $f(a)<f(x)$ for all $x\in (a,b)$. Assume
	for contradiction that $f(x)<f(a)$, note that $f(x)<f(a)<f(b)$
	so per the Intermediate Value Theorem there is $\xi\in(x,b)$
	such that $f(\xi)=f(a)$, contradicting $f$ being injective. So
	therefore $f(a)\leq f(x)$, but $f$ is injective, so $f(a)<f(x)$.

	Next let $x\in(a,b]$, then $f(a)<f(x)$, and let $x'\in(a,x)$. Aiming
	for contradiction, assume that $f(x)<f(x')$. We have that
	$f(a)<f(x)<f(x')$, so therefore per the Intermediate Value Theorem
	there is $\xi\in(a,x')$ such that $f(\xi)=f(x)$,  contradicting
	$f$ being injective. So therefore $f(x')\leq f(x)$, but since $f$ is
	injective, it must be the case that $f(x')<f(x)$.

	\textbf{Sufficient condition} (Strictly increasing $\implies$ Injective)

	Let $x\neq x'$ and without loss of generality assume $x<x'$,
	then since $f$ is strictly increasing it must be the case that
	$f(x)<f(x')$. That is $f(x)\neq f(x')$, which completes the proof.
\end{proof}
\begin{corollary}
	Let $f$ be continues on $[a,b]$ and $f(b)<f(a)$. Then $f$ is
	injective on $[a,b]$ if and only if $f$ is strictly decreasing
	on $[a,b]$. To see why, note that for $-f$ the above Theorem applies.
\end{corollary}
\begin{corollary}
	Let $f$ be continues on $[a,b]$ and $f(b)\neq f(a)$. Then $f$
	is injective on $[a,b]$ if and only if $f$ is strictly increasing
	or decreasing on $[a,b]$.
\end{corollary}
\begin{theorem}
	Let $f$ be continues and even on $\R$. Then there is $N\in\R$ such that for
	all $x\in\R$ we have either $f(x)\leq N$ or $N\leq f(x)$.
\end{theorem}
\begin{proof}
	Assume first that $f$ is unbounded above. We note that since
	the continues image of a closed interval is bounded, that $f$
	cannot be unbounded near some $a\in\R$. Therefore it must be
	the case that
	\begin{equation}
	\begin{aligned}
		\lim_{x\rightarrow +\infty}f(x)=+\infty\text{ or }
		\lim_{x\rightarrow -\infty}f(x)=+\infty
	\end{aligned}
	\end{equation}
	Note that
	\begin{equation}
	\begin{aligned}
		\lim_{x\rightarrow -\infty}f(x)=\lim_{x\rightarrow \infty}f(-x)=
		\lim_{x\rightarrow \infty}f(x)
	\end{aligned}
	\end{equation}
	therefore $f$ must be bounded below. It is easy to see that a similar
	argument holds when $f$ is unbounded below, showing that $f$ is bounded
	above. Lastly if $f$ is bounded, there is nothing to show.
\end{proof}
\begin{align*}
	i^i&=e^{i\ln i}\\
	i&=e^{\pi i/2}\\
	\ln i&=\pi i/2\\
	i^i&=e^{-\pi/2}\\
	\\
	\sqrt{i}&=i^{1/2}\\
			&=e^{\pi i/4}\\
	\\
	e^{\ln\left(x^y\right)}=x^y&={\left(e^{\ln x}\right)}^y=e^{y\ln x}\\
	\therefore \ln\left(e^{\ln\left(x^y\right)}\right)
	&=\ln\left(e^{y\ln x}\right)\\
	\implies \ln\left(x^y\right)&=y\ln x
\end{align*}
\begin{align*}
	i^i&=e^{i\ln i}\\
	i&=e^{\pi i/2}\\
	\ln i&=\pi i/2\\
	i^i&=e^{-\pi/2}\\
	\\
	\sqrt{i}&=i^{1/2}\\
			&=e^{\pi i/4}\\
	\\
	e^{\ln\left(x^y\right)}=x^y&={\left(e^{\ln x}\right)}^y=e^{y\ln x}\\
	\therefore \ln\left(e^{\ln\left(x^y\right)}\right)
	&=\ln\left(e^{y\ln x}\right)\\
	\implies \ln\left(x^y\right)&=y\ln x
\end{align*}
\begin{definition}[Polynomial vector space]
	Given some polynomial 
	\begin{equation}
	\begin{aligned}	
		P(x) = a_n x^n+a_{n-1} x^{n-1}+\cdots+a_1x+a_0
	\end{aligned}	
	\end{equation}
	Where $a_i$ is non zero. We define the corresponding vector as follows
	\begin{equation}
	\begin{aligned}	
		\begin{pmatrix}
			a_0 \\
			a_1 \\
			\vdots \\
			a_n \\
			0 \\
			\vdots
		\end{pmatrix}
	\end{aligned}	
	\end{equation}
	Addition is defined in the usual way for polynomials and the same for
	multiplication by a scalar. It's easy then to see that it forms a vector
	space.
\end{definition}
\begin{equation}
\begin{aligned}	
	\begin{bmatrix}a & b\\c & d\end{bmatrix}\begin{pmatrix}x \\y\end{pmatrix}
					 &=
	\begin{bmatrix}
		a & b \\
		c & d
	\end{bmatrix}
	\left(
	x
	\begin{pmatrix}
		1 \\
		0
	\end{pmatrix}
	+
	y
	\begin{pmatrix}
		0 \\
		1
	\end{pmatrix}
	\right)\\
	&=
	x\begin{pmatrix}a \\c\end{pmatrix}
	+y\begin{pmatrix}b \\d\end{pmatrix}\\
	&=\begin{pmatrix}ax+by \\cx+dy\end{pmatrix}


\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\mathcal{F}\{f(t)\}&:=\int_{-\infty}^\infty f(t)e^{-2\pi it\xi}\ \dx t\\
	\mathcal{L}\{f(t)\}&:=\int_0^\infty e^{-st}f(t)\ \dx t\\
	\mathcal{B}\{f(t)\}&:=\int_{-\infty}^{\infty}e^{-st}f(t)\ \dx t\\
	\mathcal{M}\{f(t)\}&:=\int_0^\infty t^{s-1}f(t)\ \dx t\\
\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\mathcal{L}\{\cos (at)\} &= \int_0^\infty \cos(at)e^{-st}\ \dx t\\
	 					   &= \int_0^\infty \cos(at)e^{-st}\ \dx t\\
						   &=-\frac{1}{s}\cos(at)e^{-st}\big|_0^\infty
	-\frac{a}{s}\int_0^\infty \sin(at)e^{-st}\ \dx t\\
	&= \frac{1}{s}-\frac{a}{s}\left(-\frac{1}{s}\sin(at)e^{-st}\big|_0^\infty
+\frac{a}{s}\int_0^\infty \cos(at)e^{-st}\right)\\
&=\frac{1}{s}-\frac{a^2}{s^2}\mathcal{L}\{\cos (at)\}\\
\therefore \mathcal{L}\{\cos (at)\} &=\frac{1}{s}
					-\frac{a^2}{s^2}\mathcal{L}\{\cos (at)\}\\
\mathcal{L}\{\cos (at)\}\frac{s^2+a^2}{s^2} &=\frac{1}{s}\\		
\mathcal{L}\{\cos (at)\} &= \frac{s}{a^2+s^2}
\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\mathcal{L}\{e^{at}\} &= \int_0^\infty e^{at} e^{-st}\ \dx t\\
						 &= \int_0^\infty e^{(a-s)t}\ \dx t\\
						 &= \frac{e^{(a-s)t}}{(a-s)}\bigg|_0^\infty
	= \frac{1}{s-a}
\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\frac{\dx}{\dx t}\int_a^b f(x,t)\ \dx x = 
	\int_a^b \frac{\del f}{\del t}(x,t)\ \dx x
\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\mathcal{L}\{tf(t)\} &= \int_0^\infty tf(t)e^{-st}\ \dx t\\
	\frac{\dx}{\dx s} \int_0^\infty f(t)e^{-st}\ \dx t
	&=\int_0^\infty \frac{\del}{\del s} f(t)e^{-st}\ \dx t\\
	&=-\int_0^\infty tf(t)e^{-st}\ \dx t\\
	\therefore \mathcal{L}\{tf(t)\}&=-\frac{\dx }{\dx s}\mathcal{L}\{f(t)\}
\end{aligned}	
\end{equation}
\begin{equation}
\begin{aligned}	
	\mathcal{L}\left\{\frac{f(t)}{t}\right\} 
	&= \int_0^\infty \frac{f(t)}{t}e^{-st}\ \dx t\\
	\lett tg(t) &= f(t)\\
	\mathcal{L}\{tg(t)\}&=-\frac{\dx }{\dx s}\mathcal{L}\{g(t)\}\\
	\therefore \mathcal{L}\{f(t)\}&=-\frac{\dx }{\dx s}
	\mathcal{L}\left\{\frac{f(t)}{t}\right\} \\
	\int_s^\infty \mathcal{L}\{f(t)\}\ \dx s
	&=-\mathcal{L}\left\{\frac{f(t)}{t}\right\} \bigg|^\infty_s\\
	&=\lim_{s\rightarrow\infty}\mathcal{L}\left\{\frac{f(t)}{t}\right\}
	+\mathcal{L}\left\{\frac{f(t)}{t}\right\}\\
	&=\mathcal{L}\left\{\frac{f(t)}{t}\right\}
\end{aligned}	
\end{equation}
\begin{align*}
	\cL\{t\} &= -\frac{\dx}{\dx s}\cL\{1\}\\
			 &= -\frac{\dx}{\dx s}\int_0^\infty e^{-st}\ \dx t\\
			 &= -\frac{\dx}{\dx s}{\left[-\frac{e^{-st}}{s}\right]}_0^\infty\\
			 &= -\frac{\dx}{\dx s}\frac{1}{s}=\frac{1}{s^2}\\
\end{align*}
\begin{align*}
	\cL\{t^{n-1}\} &= \frac{(n-1)!}{s^n}\\
	\cL\{t^n\} &= \cL\{tt^{n-1}\}\\
			   &= -\frac{\dx}{\dx s}\cL\{t^{n-1}\}\\
			   &= -\frac{\dx}{\dx s}\frac{(n-1)!}{s^n}\\
			   &= \frac{n!}{s^{n+1}}\\
\end{align*}
\begin{align*}
	\Gamma(z)&=\int_0^\infty x^{z-1}e^{-x}\ \dx x\\
	\Gamma(1)&=\int_0^\infty e^{-x}\ \dx x={\left[-e^{-x}\right]}_0^\infty=1\\
	\text{Assume }\Gamma(n-1)&=(n-2)!\\
	\Gamma(n)&=\int_0^\infty x^{n-1}e^{-x}\ \dx x\\
			 &={\left[-x^{n-1}e^{-x}\right]}_0^\infty
	+(n-1)\int_0^\infty x^{n-2}e^{-x}\ \dx x\\
	&=(n-1)\int_0^\infty x^{n-2}e^{-x}\ \dx x\\
	&=(n-1)!\\
	\\
	\Gamma'(z)&=\frac{\dx}{\dx z}\int_0^\infty x^{z-1}e^{-x}\ \dx x\\
	          &=\int_0^\infty \frac{\del}{\del z}x^{z-1}e^{-x}\ \dx x\\
			  &=\int_0^\infty \ln(x)e^{z-1}e^{-x}\ \dx x\\
\end{align*}
\newline
\begin{align*}
	I&=\int_0^\infty \frac{\sin t}{t}\ \dx t\\
	\cL\left\{\frac{\sin t}{t}\right\}(s)
	&=\int_0^\infty\frac{\sin t}{t}e^{-st}\ \dx t \\
	\therefore \cL\left\{\frac{\sin t}{t}\right\}(0)
	&=\int_0^\infty\frac{\sin t}{t}\ \dx t \\
	\cL\left\{\frac{\sin t}{t}\right\}(s)
	&=\int_s^\infty\cL\{\sin t\}(u)\ \dx u \\
	&=\int_s^\infty\frac{1}{1+u^2}\ \dx u \\
	&={\left[\arctan u\right]}_s^\infty \\
	&=\frac{\pi}{2}-\arctan s \\
	\therefore \int_0^\infty\frac{\sin t}{t}\ \dx t
	&=\cL\left\{\frac{\sin t}{t}\right\}(0)\\
	&=\frac{\pi}{2}
\end{align*}
\newline
\begin{align*}
	I&=\int_0^\infty \frac{\sin^2 x}{x^2(x^2+1)}\ \dx x\\
	\frac{A}{x^2}+\frac{B}{x^2+1}&=\frac{1}{x^2(x^2+1)}\\
	A+Ax^2+Bx^2&=1\implies B=-A\\
	\therefore A&=1\\
	I&=\int_0^\infty \frac{\sin^2 x}{x^2}\ \dx x
	-\int_0^\infty \frac{\sin^2 x}{x^2+1}\ \dx x\\
	J_1(a)&=\int_0^\infty \frac{\sin^2 (ax)}{x^2}\ \dx x\\
	J_1'(a)&=\int_0^\infty \frac{2\sin(ax)\cos(ax)}{x}\ \dx x\\
		   &=\int_0^\infty \frac{\sin(2ax)}{x}\ \dx x=\frac{\pi}{2}\\
	\int_0^a J_1'(a')\ \dx a'&=J_1(a)-J_1(0)=J_1(a)=\frac{\pi a}{2}\\
	\therefore J_1(1)=\frac{\pi}{2}&=\int_0^\infty\frac{\sin^2x}{x^2}\ \dx x\\
	I&=\frac{\pi}{2}
	-\int_0^\infty \frac{\sin^2 x}{x^2+1}\ \dx x\\
	J_1&=\int_0^\infty \frac{\sin^2 x}{x^2+1}\ \dx x\\
	&=\frac{1}{2}\int_0^\infty \frac{1-\cos (2x)}{x^2+1}\ \dx x\\
	&=\frac{\pi}{4}-\frac{1}{2}\int_0^\infty \frac{\cos (2x)}{x^2+1}\ \dx x\\
	&=\frac{\pi}{4}-\frac{1}{2}\int_0^\infty \frac{2\cos^2 x-1}{x^2+1}\ \dx x\\
	&=\frac{\pi}{2}-\int_0^\infty \frac{\cos^2 x}{x^2+1}\ \dx x\\
	&=\frac{\pi}{2}-\frac{1}{2}\int_0^\infty \frac{e^{2xi}+e^{-2xi}+2}{x^2+1}\ \dx x\\
\end{align*}
\begin{align*}
	\int_{\del \Omega} \omega = \int_{\Omega} \dx \omega
\end{align*}
\newpage
\section{Construction of $\N$}
\begin{definition}[Axioms of $\N$]\label{nat axioms}
	Let $\N$ be a set with the following properties
	\begin{align*}
		(P1)\; &:\quad \exists 0\in\N\\
		(P2)\; &:\quad \exists S:\N\rightarrow\N\\
		(P3)\; &:\quad \forall m,n\in\N &&: S(m)=S(n)\implies m=n\\
		(P4)\; &:\quad \forall n\in\N &&: S(n)\neq 0\\
		(P5)\; &:\quad \forall N\subseteq\N &&: 
		(0\in N\land(\forall n\in N:s(n)\in N))\implies N=\N\\
	\end{align*}
\end{definition}
\begin{theorem}\label{nat proof}
	There exists a set $\N$ satisfying the axioms of
	definition~\ref{nat axioms}.
\end{theorem}
\begin{proof}
	Let $0=\emptyset$ and let $S(n)=\{n\}\cup n$. We claim that the set
	\begin{align*}
		\N =\{n:n=0\lor\exists m\in\N:S(m)=n\}
	\end{align*}
	satisfies the axioms of definition~\ref{nat axioms}. First note
	that $(P1)$ and $(P2)$ are already satisfied. For $(P3)$ we let
	$m,n\in\N$. Then assume
	\begin{align*}
		S(m)&=S(n)\iff \{m\}\cup m=\{n\}\cup n
	\end{align*}
	thus we have $n\in S(m)$. If $n\in\{m\}$ then we are done, so
	assume $n\in m$. Then $m\neq n$ by the Axiom of Foundation. We
	have $m\in \{m\}$ so by the Axiom of Extension and Axiom of
	Unions we have $m\in S(n)$. Since $n\neq m$ we must have $m\in
	n$ contradicting the Axiom of Foundation. We therefore conclude
	that $n=m$. $(P4)$ is trivially satisfied by the Axiom of the
	Empty Set. For the last $(P5)$ we can see that $\forall n\in
	N:s(n)\in N$ implies that $\exists m\in N$ such that $S(m)=n$
	for all $n \in N$. But that is just the definition of $\N$
	which completes the proof.
\end{proof}
\begin{theorem}[Proof by induction]\label{induction}
	Let $p(n)$ be a proposition defined for all $n\in \N$. If
	\begin{align*}
		p(0) \land p(n)\implies p(S(n))\\
	\end{align*}
	Then $p$ is true for all $n\in \N$.
\end{theorem}
\begin{proof}
	Consider the set $A$ defined as
	\begin{align*}
		A=\{n\in\N:p(n)\}
	\end{align*}
	By assumption $0\in A$ and for any $n\in A$, we have that
	$S(n)\in\N$ since \newline$p(n)\implies p(S(n))$. Therefore $A$
	may equivilantly be defined as
	\begin{align*}
		A=\{n\in\N:n=0\lor\exists m\in\N:S(m)=n\}
	\end{align*}
	But that is the definition of $\N$, so since $A$ may equivalently
	be defined as the set of $n\in\N$ such that $p(n)$ this completes
	the proof.
\end{proof}
\begin{definition}[Addition on $\N$]\label{addition}
	Let $+:\N^2\rightarrow\N$ we define \textit{addition} as
	follows
	\begin{align*}
	\forall n,m\in\N:
	\begin{cases}
		m+0 & = m \\
		m+S(n) &= S(m+n)
	\end{cases}
	\end{align*}
\end{definition}
\begin{theorem}
	Let $+$ be the operator as defined in definition~\ref{addition}. Then $+$
	satisfies
	\begin{align*}
		(G0)\; &:\quad \forall n,m\in\N &&:n+m\in\N 
		&&&\text{(Totality)}\\
		(G1)\; &:\quad \forall n,m,k\in\N&&:n+(m+k)=(n+m)+k
		&&&\text{(Associativity)}\\
		(G2)\; &:\quad \exists 0:\forall n\in\N &&: n+0=0+n=n 
		&&&\text{(Identity)}\\
		(C)\; &:\quad \forall n,m\in\N &&: n+m=m+n
		&&&\text{(Commutativity)}\\
	\end{align*}
\end{theorem}
\begin{proof}\
\begin{itemize}
	\item[] $(G0)\ $: This property follows from Theorem~\ref{nat
		proof}. Notice that in the case $m+0=m$, by definition
		$m+0\in\N$. Assume then for $n\in\N$ that $m+n\in\N$,
		then we have $m+S(n)=S(m+n)$ and since $m+n\in\N$,
		by Theorem~\ref{nat proof}. By Theorem~\ref{induction}
		and that $m$ was arbitrary this shows $(G0)$.
	\item[] $(G1)\ $: Notice that if any of $n,m,k\in\N$ this 
		property holds. So assume $n,m,k\neq 0$. This implies that
		for all of them there is some $n',m',k'\in\N$ such that
		$n=S(n')$ and equivalently for the others. So we may write
		\begin{align*}
			n+(m+k) &= S(n')+(m+k)\\
					&= S(n'+(m+k))\\
			(n+m)+k &= (n+m)+S(k')\\
					&= S((n+m)+k')\\
		\end{align*}
		So if $n'+(m+k)=(n+m)+k'$ this property follows. If
		$n'=0$ then
		\begin{align*}
			n'+(m+k)=m+k&=(n'+m)+k\\
						&=(n'+m)+S(k')\\
						&=S((n'+m)+k')\\
						&=S(n'+m)+k'\\
						&=n+m+k'\\
		\end{align*}
		the argument if $k'=0$ is similarly. If, on the other
		hand $k',n'\neq0$ repeat the process described earlier
		and note that eventually one of the must be equal to $0$.
	\item[] $(G2)\ $: This property follows trivially.
	\item[] $(C0)\ $:
\end{itemize}
\end{proof}
\begin{definition}[Order on $\N$]\label{order}
	We define an order on $\N$ as follows
	\begin{align*}
		\forall n,m\in\N:n\leq m:= \exists c\in\N:n+c=m
	\end{align*}
\end{definition}
\begin{theorem}[Order on $\N$ is total order]\label{well-ordered}
	Let $\leq$ be the order as defined in definition~\ref{order}. Then $\leq$
	satisfies
	\begin{align*}
		(0)\; &:\quad \forall n\in\N &&: n\leq n
		&&&\text{(Reflexive)}\\
		(1)\; &:\quad \forall n,m,k\in\N&&:n\leq m\land m\leq k\implies n\leq k
		&&&\text{(Transitive)}\\
		(2)\; &:\quad \forall n,m\in\N &&:n\leq m\land m\leq n \implies n=m
		&&&\text{(Antisymmetric)}\\
		(2)\; &:\quad \forall n,m\in\N &&:n\leq m\lor m\leq n
		&&&\text{(Connected)}\\
	\end{align*}
\end{theorem}
\begin{proof}
\end{proof}
\begin{theorem}[$\N$ is well-ordered]\label{well-ordered}
	Every subset of $N$ contains a least member.
	\begin{align*}
		\forall N\subseteq \N: \exists n\in N: \forall m\in\N: n\leq m
	\end{align*}
\end{theorem}
\begin{proof}
\end{proof}
\newpage
\begin{align*}
	&\forall a,b\in\R^n:S(x,y)=\prod_{i=1}^n [x_i,y_i]\\
	&\forall a,b\in\R^n:\mu (x,y)=\prod_{i=1}^n |x_i-y_i|\\
	&\forall X\subseteq\R^n: \lambda(X)
	=\inf \left\{\sum_{i=1}^n \mu(x,y):X\subseteq \bigcup_{i=1}^n S(x,y)\land
	n\in\N\right\}
\end{align*}
\section{Euclidean algebra}
Point: $A\in\R^2$.\newline
Distance: $A,B\in\R^2:|AB|:=\sqrt{{(A_1-B_1)}^2+{(A_2-B_2)}^2}$\newline
Line: $A,B\in\R^2: \overline{AB}:=\{tx+sy:t+s=1\land 0\leq t,s\leq 1\}$\newline
Circle: $A,B,O\in\R^2:c(A,B,):=\{C\in\R^2:|OC|=|AB|\}$\newline
Intersection: $A,B\in\R^2: A\mid B:= C:C$
\newpage
\begin{definition}[Gradient]
	Let $f:\R^n\rightarrow\R$, $\mathbf{x}\mapsto f(\mathbf{x})$ where:
\begin{align*}
	\mathbf{x}=
		\begin{bmatrix}
			x_1 \\
			x_2 \\
			\vdots \\
			x_n \\
		\end{bmatrix}
\end{align*}
Let $\frac{\del f}{\del x_i}$ exists for all $x_i$. The \textbf{gradient of $f$
(at $\mathbf{x}$)} is defined as the column matrix:
\begin{align*}
	\nabla f(\mathbf{x})=
		\begin{bmatrix}
			\frac{\del f(\mathbf{x})}{\del x_1} \\
			\frac{\del f(\mathbf{x})}{\del x_2} \\
			\vdots \\
			\frac{\del f(\mathbf{x})}{\del x_n} \\
		\end{bmatrix}
\end{align*}
\end{definition}
\begin{align*}
	\underset{i=k\rightarrow n}{[+a_i]} &= 
	\begin{cases}
		\underset{i=k\rightarrow n-1}{[+a_i]}+a_n & k\leq n\\
		0 & n < k
	\end{cases}
\end{align*}
\begin{align*}
	\underset{i=1\rightarrow n}{[+i]}=\frac{n(n+1)}{2}\\
	\underset{i=k\rightarrow n}{[+a_i]}+\underset{i=k\rightarrow n}{[+b_i]}
	=\underset{i=k\rightarrow n}{[+a_i+b_i]}\\
	\underset{i=k\rightarrow n}{[+a_i]}\cdot\underset{i=k\rightarrow n}{[+b_i]}=
	\underset{i=k\rightarrow n,\ i=k\rightarrow n}{[+a_i\cdot[+b_i]]}
\end{align*}
\newpage
\begin{enumerate}
	\item First postulate (principle of relativity)

		The laws of physics are the same in all inertial frames of reference.
	\item Second postulate (invariance of $c$)

		The speed of light in free space has the same value $c$
		in all inertial frames of reference.
\end{enumerate}
\begin{definition}[Space time]
	Space time is the Cartesian product $\R^3\times \mathbb{T}$ where
	$\mathbb{T}$ is the time domain $\mathbb{T}=\R$. That is any event may be
	indicated by its $xyz$-coordiantes and the time at which it occurred,
	formally:
	\begin{align*}
		(x,y,z,t)\in\R^3 \times \mathbb{T}\\
	\end{align*}
\end{definition}
\begin{definition}[Reference frame]
	A reference frame is a function $F$ such that for all $t\in\mathbb{T}$ we
	have $F(t)=(0,0,0)$. Intuitively this means that any object is distance zero
	from itself.
\end{definition}
\begin{definition}[World line]
	A world line is a function $W:\mathbb{T}\rightarrow \R^3$ such that if
	$W(t)=(x,y,z)$ then
	\begin{align*}
	v^2 t^2=x^2+y^2+z^2 \\
	\end{align*}
	where $v$ is the velocity of the object relative to the reference
	frame. This is equivalent to saying that the distance traveled
	from $t=0$ at speed $v$ equals the distance from the reference frame.
\end{definition}
Note that the reference frame is a special world line.
\begin{definition}[Transformation of reference frame]
	Given a world line $W$ there exists a transformation $L:
	\R^3\times\mathbb{T}\rightarrow\R^3\times\mathbb{T}$ 
	such that:
	\begin{enumerate}
		\item $L(W)$ is a reference frame.
		\item If world lines $W_1$ and $W_2$ have relative velocity $v$, then so
			do $L(W_1)$ and $L(W_2)$.
		\item For some constant $c\in\R_{>0}$ describe the world line $W$ with
			relative velocity $c$ to the reference frame $F$. Then the relative
			velocity to $L(W)$ is also $c$.
	\end{enumerate}
\end{definition}
\subsection{Special case}
\newpage
\begin{align*}
	a^2-a&=a(a-1)\\
	a^2-a&\equiv a(a-1) \pmod{2}\\
	a^2-a&\equiv 0 \pmod{2}\\
	a^2&\equiv a \pmod{2}\\
\end{align*}
\begin{align*}
	a,b,c\in\N: a^2+b^2&=4c+3\\
	a^2+b^2&\equiv 3 \pmod{4}\\
	a^2,b^2 &\in \{0,1,0,1\}
\end{align*}
\begin{align*}
	\forall n\in\N:\forall a\in\N: a^n &\equiv a \pmod{n}\\
\end{align*}
\begin{enumerate}
	\item Open-source, github like, paper writing.
	\item Issue tracker with monetary awards?
	\item Programming build in, jupyter like.
\end{enumerate}
\newpage
\begin{align*}
	a,b,c\in\N: a^2+b^2&=4c+3\\
	a^2+b^2&\equiv 3 \pmod{4}\\
	a^2,b^2 &\in \{0,1,0,1\}
\end{align*}
\begin{align*}
	&M = \{v_1,v_2,\dots,v_n\}\subset\R^2:\\
	&\rightarrow v_1+v_2+\cdots+v_n = \textbf{0} \\
	&\rightarrow \forall 1\leq i\leq n : \|v_i\|\leq 1\\
	&\rightarrow \forall 1\leq i\leq n : \|v_i\|\leq 1\\
\end{align*}
\begin{align*}
	\Z/2\Z\times\Z/3\Z = \{(0,0),(0,1),(0,2),(1,0),(1,1),(1,2)\}
\end{align*}
\begin{center}
\begin{tabular}{l|llllll}
	 + & 00 & 01 & 02 & 10 & 11 & 12 \\ \hline
	00 & 00 & 01 & 02 & 10 & 11 & 12 \\
	01 & 01 & 02 & 00 & 11 & 12 & 10 \\
	02 & 02 & 00 & 01 & 12 & 10 & 11 \\
	10 & 10 & 11 & 12 & 00 & 01 & 02 \\
	11 & 11 & 12 & 10 & 01 & 02 & 00 \\
	12 & 12 & 10 & 11 & 02 & 00 & 01 \\
\end{tabular}
\end{center}
\begin{center}
\begin{tabular}{l|llllll}
	  + & $e$ & $a$ & $b$ & $c$ & $d$ & $f$ \\ \hline
	$e$ & $e$ & $a$ & $b$ & $c$ & $d$ & $f$ \\
	$a$ & $a$ & $b$ & $e$ & $d$ & $f$ & $c$ \\
	$b$ & $b$ & $e$ & $a$ & $f$ & $c$ & $d$ \\
	$c$ & $c$ & $d$ & $f$ & $e$ & $a$ & $b$ \\
	$d$ & $d$ & $f$ & $c$ & $a$ & $b$ & $e$ \\
	$f$ & $f$ & $c$ & $d$ & $b$ & $e$ & $a$ \\
\end{tabular}
\end{center}
\begin{align*}
	\exp \int \ln x\ \dx x &= \exp\left(x\ln x -x\right)\\
						   &= \frac{x^x}{e^x}
\end{align*}
\newpage
\begin{align*}
	\text{GL}_n(\R) &= \{M\in\R^{n\times n}:\exists M^{-1}\in\R^{n\times
	n}:MM^{-1}=M^{-1}M=I_n\}\\
	\text{SL}_n(\R) &= \text{ker}(\text{det}),\; \text{det}:\text{GL}_n(\R)\rightarrow\R/\{0\}
\end{align*}
\begin{theorem}
	Let $G$ be a group and let $H,N\subseteq G$ such that $H\cap
	N=\emptyset$ and $H\cup N = G$. Then $H$ and $N$ are subgroups iff
	$H{\times}N \simeq G$.
\end{theorem}
\begin{align*}
	\prod_a^b f(x)^{\dx x} &= \exp \left(\int_a^b \ln f(x)\ \dx x\right) \\
	\prod_a^b {x}^{n\ \dx x} &= \exp \left(\int_a^b \ln x^n\ \dx x\right) \\
	&= \exp \left(\int_a^b n \ln x\ \dx x\right) \\
	&= \exp \left(\int_a^b \ln x\ \dx x\right)^n \\
	&= \exp \left(\left[x\ln x - x\right]_a^b\right)^n \\
	&= \exp \left(b\ln b - b - a\ln a + a\right)^n \\
	&= e^{nb\ln b}e^{-nb}e^{-na\ln a}e^{na} \\
	&= e^{n(a-b)}b^{nb}a^{-na} \\
	\prod_1^x {x}^{n\ \dx x} &= e^{n(1-x)}x^{nx} \\
	&= e^{n(1-x)}e^{nx\ln x} \\
	&= e^{n-nx+nx\ln x} \\
	&= e^n e^{n(x\ln x - x)} \\
\end{align*}
\begin{align*}
	f(z)&=\frac{1}{z}+z\\
		&=\frac{\bar{z}}{z\bar{z}}+z\\
		&=\frac{\bar{z}}{|z|^2}+z \\
		&=\frac{\bar{z}+|z|^2z}{|z|^2}\\
		&=\frac{\bar{z}+\bar{z}z^2}{|z|^2}
\end{align*}
\begin{align*}
	I &= \int_a^b \tan x\ \dx x \\
	  &= \int_a^b \frac{\sin x}{\cos x}\ \dx x \\
	u = \cos x &\implies \dx u = -\sin x\ \dx x\\
	  &= -\int_{\cos a}^{\cos b} \frac{\dx u}{u} \\
	  &= \ln\left(\frac{\cos a}{{\cos b}}\right) \\
\end{align*}
\end{document}
